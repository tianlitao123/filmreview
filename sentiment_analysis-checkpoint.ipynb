{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于TextCNN模型的豆瓣影评情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入项目需要的相关python包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "import jieba  #分词工具包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取豆瓣影评数据\n",
    "评分大于3星的评论设定为积极情绪，小于等于3星的评论设定为消极情绪。<br>\n",
    "打印出前五行数据，这样可以看到加载的数据到底长什么样子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name_EN</th>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Crawl_Date</th>\n",
       "      <th>Number</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>然潘</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>2</td>\n",
       "      <td>更深的白色</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>3</td>\n",
       "      <td>有意识的贱民</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>4</td>\n",
       "      <td>不老的李大爷耶</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>5</td>\n",
       "      <td>ZephyrO</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>虽然从头打到尾，但是真的很无聊啊。</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Movie_Name_EN Movie_Name_CN  Crawl_Date  Number Username  \\\n",
       "ID                                                                      \n",
       "0   Avengers Age of Ultron        复仇者联盟2  2017-01-22       1       然潘   \n",
       "1   Avengers Age of Ultron        复仇者联盟2  2017-01-22       2    更深的白色   \n",
       "2   Avengers Age of Ultron        复仇者联盟2  2017-01-22       3   有意识的贱民   \n",
       "3   Avengers Age of Ultron        复仇者联盟2  2017-01-22       4  不老的李大爷耶   \n",
       "4   Avengers Age of Ultron        复仇者联盟2  2017-01-22       5  ZephyrO   \n",
       "\n",
       "          Date  Star                                            Comment  Like  \n",
       "ID                                                                             \n",
       "0   2015-05-13     0                                      连奥创都知道整容要去韩国。  2404  \n",
       "1   2015-04-24     0   非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...  1231  \n",
       "2   2015-04-26     0   2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...  1052  \n",
       "3   2015-04-23     1   《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...  1045  \n",
       "4   2015-04-22     0                                  虽然从头打到尾，但是真的很无聊啊。   723  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DMSC.csv', index_col=0)\n",
    "data = data.assign(Star=data['Star'].map(lambda x: 0 if x <=3 else 1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对影评数据进行简单的分析与采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1279892\n",
       "0     845164\n",
       "Name: Star, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Star\"].value_counts()  # 统计影评数据正负样本比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "疯狂动物城     137511\n",
       "大圣归来      133393\n",
       "后会无期      120200\n",
       "寻龙诀       113687\n",
       "你的名字      113260\n",
       "夏洛特烦恼     109162\n",
       "釜山行       102876\n",
       "爱乐之城       96620\n",
       "西游伏妖篇      91452\n",
       "小时代1       88903\n",
       "泰囧         85677\n",
       "大鱼海棠       83692\n",
       "长城         83173\n",
       "西游降魔篇      79962\n",
       "复仇者联盟      78281\n",
       "美人鱼        73882\n",
       "七月与安生      68359\n",
       "美国队长3      64410\n",
       "变形金刚4      58746\n",
       "复仇者联盟2     54153\n",
       "十二生肖       46233\n",
       "九层妖塔       44366\n",
       "小时代3       41152\n",
       "左耳         39802\n",
       "湄公河行动      35093\n",
       "栀子花开       30475\n",
       "何以笙箫默      26797\n",
       "钢铁侠1       23739\n",
       "Name: Movie_Name_CN, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Movie_Name_CN\"].value_counts()  # 统计每部电影对应的影评数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Movie_Name_EN</th>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Crawl_Date</th>\n",
       "      <th>Number</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Star</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">七月与安生</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>1012184</th>\n",
       "      <td>Soulmate</td>\n",
       "      <td>七月与安生</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>7152</td>\n",
       "      <td>陈信宏大过天</td>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>也许是七月 也许是安生 总有一颗不想稳定下来的心</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034976</th>\n",
       "      <td>Soulmate</td>\n",
       "      <td>七月与安生</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>30357</td>\n",
       "      <td>砂糖的砂</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>跟全世界路过差不多水平吧 摄影也有很大问题 全片抓不出来一帧称得上电影构图的画面 剧情理解...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032011</th>\n",
       "      <td>Soulmate</td>\n",
       "      <td>七月与安生</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>27332</td>\n",
       "      <td>马边疆</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>不喜欢，不过马思纯很好看，给两星。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Movie_Name_EN Movie_Name_CN  Crawl_Date  Number  \\\n",
       "Movie_Name_CN Star ID                                                        \n",
       "七月与安生         0    1012184      Soulmate         七月与安生  2017-01-05    7152   \n",
       "                   1034976      Soulmate         七月与安生  2017-01-05   30357   \n",
       "                   1032011      Soulmate         七月与安生  2017-01-05   27332   \n",
       "\n",
       "                           Username        Date  Star  \\\n",
       "Movie_Name_CN Star ID                                   \n",
       "七月与安生         0    1012184   陈信宏大过天  2016-10-13     0   \n",
       "                   1034976     砂糖的砂  2016-11-07     0   \n",
       "                   1032011      马边疆  2016-11-08     0   \n",
       "\n",
       "                                                                      Comment  \\\n",
       "Movie_Name_CN Star ID                                                           \n",
       "七月与安生         0    1012184                           也许是七月 也许是安生 总有一颗不想稳定下来的心   \n",
       "                   1034976   跟全世界路过差不多水平吧 摄影也有很大问题 全片抓不出来一帧称得上电影构图的画面 剧情理解...   \n",
       "                   1032011                                  不喜欢，不过马思纯很好看，给两星。   \n",
       "\n",
       "                            Like  \n",
       "Movie_Name_CN Star ID             \n",
       "七月与安生         0    1012184     0  \n",
       "                   1034976     0  \n",
       "                   1032011     1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于数据量太大，会导致训练很慢，我们可以从原始数据中按比例采样出部分数据，加快训练过程\n",
    "# 当然如果有时间，可以用全部数据进行训练\n",
    "# 以下是数据采样的代码，采样完以后展示采样的数据\n",
    "sample_df = data.groupby(['Movie_Name_CN', 'Star']).apply(\n",
    "    lambda x: x.sample(n=int(2125056/(28*200)), replace=True, random_state=0))\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理阶段\n",
    "1. 需要先把数据分成训练集和验证集，训练集用来训练模型，验证集用来检验模型学习的阶段性成果。\n",
    "2. 使用正则表达式清理非中文字符。\n",
    "3. 对影评文本进行分词。\n",
    "4. 分词的同时加载停用词词典，过滤影评中的停用词\n",
    "5. 制作词典，对影评语料的每一个词赋予一个整型编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16979, 4245, 16979, 4245)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = sample_df.values[:, 7]\n",
    "star = sample_df.values[:, 6]\n",
    "\n",
    "x_train, x_test, y_train, y_test, = train_test_split(comments, star, test_size=0.2, random_state=0)\n",
    "\n",
    "len(y_train), len(y_test), len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 看完我也没有热泪盈眶，故事大概讲的是梦想与儿女情长（这是句废话，大部分电影都讲这些），情说的多了，我看的就有点累。好故事与讲好一个故事，它的好更偏向于后者（我觉得）。最后的蒙太奇堪比黄粱一梦。关于我们未发生的故事，都在我的琴键下，当最后一个音弥散于梦里，消失在空气里，你我都得醒。',\n",
       "       ' 硬伤不少，但是这样强大的阵容和欢脱的情节我实在是不想说什么了！ps. 习惯用男演员加标签的我加的好崩溃！ IMAX 3D 2012.5.7'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 清理非中文字符\n",
    "def clean_str(line):\n",
    "    line.strip('\\n')\n",
    "    line = re.sub(r\"[^\\u4e00-\\u9fff]\", \"\", line)\n",
    "    line = re.sub(\n",
    "        \"[0-9a-zA-Z\\-\\s+\\.\\!\\/_,$%^*\\(\\)\\+(+\\\"\\')]+|[+——！，。？、~@#￥%……&*（）<>\\[\\]:：★◆【】《》;；=?？]+\", \"\", line)\n",
    "    return line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stopWord.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-11b9e91d1d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 加载停用词\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopWord.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stopWord.txt'"
     ]
    }
   ],
   "source": [
    "# 加载停用词\n",
    "with open('stopWord.txt') as f:\n",
    "    stopwords = [line.strip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def cut(text_data, labels, stopwords):\n",
    "    result = []\n",
    "    new_labels = []\n",
    "    for index in tqdm_notebook(range(len(text_data))):\n",
    "        comment = clean_str(text_data[index])\n",
    "        label = labels[index]\n",
    "        # 分词\n",
    "        seg_list = jieba.cut(comment, cut_all=False, HMM=True)\n",
    "        seg_list = [x.strip('\\n')\n",
    "                    for x in seg_list if x not in stopwords and len(x) > 1]\n",
    "        if len(seg_list) > 1:\n",
    "            result.append(seg_list)\n",
    "            new_labels.append(label)\n",
    "    # 返回分词结果和对应的标签\n",
    "    return result, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 分别对训练数据和测试数据分词\n",
    "train_cut_result, train_labels = cut(x_train, y_train, stopwords)\n",
    "test_cut_result, test_labels = cut(x_test, y_test, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "len(train_cut_result), len(train_labels), len(test_cut_result), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_cut_result[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_labels[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_cut_result[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_labels[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = train_cut_result + test_cut_result\n",
    "word2index = {}\n",
    "vocab_count = 0\n",
    "for sent in vocab:\n",
    "    for v in sent:\n",
    "        if v not in word2index:\n",
    "            word2index[v] = vocab_count\n",
    "            vocab_count += 1\n",
    "print(\"vocabulary size: {}\".format(vocab_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for k in list(word2index.keys())[:10]:\n",
    "    print(\"{}: {}\".format(k, word2index[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据和验证数据准备阶段\n",
    "1. 对每一条训练数据分词，去停用词。\n",
    "2. 将词应设为其在词典中对应的编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for sent in train_cut_result:\n",
    "    x_train.append([word2index[v] for v in sent])\n",
    "x_train[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "len(x_train), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for sent in test_cut_result:\n",
    "    x_test.append([word2index[v] for v in sent])\n",
    "x_test[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "len(x_test), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入训练模型需要的深度学习框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from text_cnn import TextCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 设置模型参数\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Pad sequences (samples x time)...')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = TextCNN(maxlen, vocab_count, embedding_dims).get_model()\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3, mode='max')\n",
    "# 设置保存训练好的模型的名字\n",
    "checkpointer = ModelCheckpoint('montion_best.h5', verbose=1, save_best_only=True)\n",
    "print(len(x_test), len(test_labels))\n",
    "model.fit(x_train, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[early_stopping, checkpointer],\n",
    "          validation_data=(x_test, test_labels))\n",
    "\n",
    "model.save(\"montion_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sample_text = \"不喜欢，不过马思纯很好看，给两星。\"\n",
    "tmp_text = clean_str(sample_text)\n",
    "seg_list = jieba.cut(tmp_text, cut_all=False, HMM=True)\n",
    "seg_list = [x.strip('\\n') for x in seg_list if x not in stopwords and len(x) > 1]\n",
    "seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seg_list = [word2index[v] for v in seg_list]\n",
    "seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seg_list = seg_list+[0]*(maxlen-len(seg_list)) if len(seg_list) <= 80 else seg_list[:80]\n",
    "seg_list = np.array([seg_list])\n",
    "print(seg_list.shape)\n",
    "result = model.predict(seg_list)\n",
    "print(result)\n",
    "if result[0] > 0.5:\n",
    "    print(\"积极\")\n",
    "else:\n",
    "    print(\"消极\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
